{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fit in Linear Regression - Lab\n",
    "\n",
    "## Introduction\n",
    "In this lab, you'll learn how to evaluate your model results and you'll learn how to select the appropriate features using stepwise selection.\n",
    "\n",
    "## Objectives\n",
    "You will be able to:\n",
    "* Use stepwise selection methods to determine the most important features for a model\n",
    "* Use recursive feature elimination to determine the most important features for a model\n",
    "\n",
    "## The Boston Housing Data once more\n",
    "\n",
    "We pre-processed the Boston Housing data the same way we did before:\n",
    "\n",
    "- We dropped `'ZN'` and `'NOX'` completely\n",
    "- We categorized `'RAD'` in 3 bins and `'TAX'` in 4 bins\n",
    "- We transformed `'RAD'` and `'TAX'` to dummy variables and dropped the first variable\n",
    "- We used min-max-scaling on `'B'`, `'CRIM'`, and `'DIS'` (and logtransformed all of them first, except `'B'`)\n",
    "- We used standardization on `'AGE'`, `'INDUS'`, `'LSTAT'`, and `'PTRATIO'` (and logtransformed all of them first, except for `'AGE'`) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "\n",
    "boston_features = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "boston_features = boston_features.drop(['NOX', 'ZN'],axis=1)\n",
    "\n",
    "# First, create bins for based on the values observed. 3 values will result in 2 bins\n",
    "bins = [0,6,  24]\n",
    "bins_rad = pd.cut(boston_features['RAD'], bins)\n",
    "bins_rad = bins_rad.cat.as_unordered()\n",
    "\n",
    "# First, create bins for based on the values observed. 4 values will result in 3 bins\n",
    "bins = [0, 270, 360, 712]\n",
    "bins_tax = pd.cut(boston_features['TAX'], bins)\n",
    "bins_tax = bins_tax.cat.as_unordered()\n",
    "\n",
    "tax_dummy = pd.get_dummies(bins_tax, prefix='TAX', drop_first=True)\n",
    "rad_dummy = pd.get_dummies(bins_rad, prefix='RAD', drop_first=True)\n",
    "boston_features = boston_features.drop(['RAD', 'TAX'], axis=1)\n",
    "boston_features = pd.concat([boston_features, rad_dummy, tax_dummy], axis=1)\n",
    "\n",
    "age = boston_features['AGE']\n",
    "b = boston_features['B']\n",
    "logcrim = np.log(boston_features['CRIM'])\n",
    "logdis = np.log(boston_features['DIS'])\n",
    "logindus = np.log(boston_features['INDUS'])\n",
    "loglstat = np.log(boston_features['LSTAT'])\n",
    "logptratio = np.log(boston_features['PTRATIO'])\n",
    "\n",
    "# Min-Max scaling\n",
    "boston_features['B'] = (b-min(b))/(max(b)-min(b))\n",
    "boston_features['CRIM'] = (logcrim-min(logcrim))/(max(logcrim)-min(logcrim))\n",
    "boston_features['DIS'] = (logdis-min(logdis))/(max(logdis)-min(logdis))\n",
    "\n",
    "# Standardization\n",
    "boston_features['AGE'] = (age-np.mean(age))/np.sqrt(np.var(age))\n",
    "boston_features['INDUS'] = (logindus-np.mean(logindus))/np.sqrt(np.var(logindus))\n",
    "boston_features['LSTAT'] = (loglstat-np.mean(loglstat))/np.sqrt(np.var(loglstat))\n",
    "boston_features['PTRATIO'] = (logptratio-np.mean(logptratio))/(np.sqrt(np.var(logptratio)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RAD_(6, 24]</th>\n",
       "      <th>TAX_(270, 360]</th>\n",
       "      <th>TAX_(360, 712]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.704344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.575</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.542096</td>\n",
       "      <td>-1.443977</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.275260</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.153211</td>\n",
       "      <td>-0.263239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.421</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.623954</td>\n",
       "      <td>-0.230278</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.263711</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.153134</td>\n",
       "      <td>-0.263239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.185</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.623954</td>\n",
       "      <td>-0.230278</td>\n",
       "      <td>0.989737</td>\n",
       "      <td>-1.627858</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.171005</td>\n",
       "      <td>-1.778965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.998</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>0.707895</td>\n",
       "      <td>0.165279</td>\n",
       "      <td>0.994276</td>\n",
       "      <td>-2.153192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.250315</td>\n",
       "      <td>-1.778965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.147</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>0.707895</td>\n",
       "      <td>0.165279</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.162114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.240099</td>\n",
       "      <td>0.410792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.593</td>\n",
       "      <td>0.018673</td>\n",
       "      <td>0.331081</td>\n",
       "      <td>1.095518</td>\n",
       "      <td>0.987619</td>\n",
       "      <td>-0.169811</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.206118</td>\n",
       "      <td>0.410792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.120</td>\n",
       "      <td>0.288933</td>\n",
       "      <td>0.297277</td>\n",
       "      <td>1.095518</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.274682</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.236926</td>\n",
       "      <td>0.410792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.976</td>\n",
       "      <td>0.797449</td>\n",
       "      <td>0.274575</td>\n",
       "      <td>1.095518</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.067939</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.298671</td>\n",
       "      <td>0.410792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.794</td>\n",
       "      <td>0.736996</td>\n",
       "      <td>0.315551</td>\n",
       "      <td>1.095518</td>\n",
       "      <td>0.991301</td>\n",
       "      <td>-0.836660</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.210954</td>\n",
       "      <td>0.410792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.030</td>\n",
       "      <td>0.434732</td>\n",
       "      <td>0.335545</td>\n",
       "      <td>1.095518</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.510809</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM     INDUS  CHAS     RM       AGE       DIS   PTRATIO         B  \\\n",
       "0    0.000000 -1.704344   0.0  6.575 -0.120013  0.542096 -1.443977  1.000000   \n",
       "1    0.153211 -0.263239   0.0  6.421  0.367166  0.623954 -0.230278  1.000000   \n",
       "2    0.153134 -0.263239   0.0  7.185 -0.265812  0.623954 -0.230278  0.989737   \n",
       "3    0.171005 -1.778965   0.0  6.998 -0.809889  0.707895  0.165279  0.994276   \n",
       "4    0.250315 -1.778965   0.0  7.147 -0.511180  0.707895  0.165279  1.000000   \n",
       "..        ...       ...   ...    ...       ...       ...       ...       ...   \n",
       "501  0.240099  0.410792   0.0  6.593  0.018673  0.331081  1.095518  0.987619   \n",
       "502  0.206118  0.410792   0.0  6.120  0.288933  0.297277  1.095518  1.000000   \n",
       "503  0.236926  0.410792   0.0  6.976  0.797449  0.274575  1.095518  1.000000   \n",
       "504  0.298671  0.410792   0.0  6.794  0.736996  0.315551  1.095518  0.991301   \n",
       "505  0.210954  0.410792   0.0  6.030  0.434732  0.335545  1.095518  1.000000   \n",
       "\n",
       "        LSTAT  RAD_(6, 24]  TAX_(270, 360]  TAX_(360, 712]  \n",
       "0   -1.275260            0               1               0  \n",
       "1   -0.263711            0               0               0  \n",
       "2   -1.627858            0               0               0  \n",
       "3   -2.153192            0               0               0  \n",
       "4   -1.162114            0               0               0  \n",
       "..        ...          ...             ...             ...  \n",
       "501 -0.169811            0               1               0  \n",
       "502 -0.274682            0               1               0  \n",
       "503 -1.067939            0               1               0  \n",
       "504 -0.836660            0               1               0  \n",
       "505 -0.510809            0               1               0  \n",
       "\n",
       "[506 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform stepwise selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function for stepwise selection is copied below. Use this function provided on your preprocessed Boston Housing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\" Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  LSTAT                          with p-value 9.27989e-122\n",
      "Add  RM                             with p-value 1.98621e-16\n",
      "Add  PTRATIO                        with p-value 2.5977e-12\n",
      "Add  DIS                            with p-value 2.85496e-09\n",
      "Add  B                              with p-value 2.77572e-06\n",
      "Add  INDUS                          with p-value 0.0017767\n",
      "Add  CHAS                           with p-value 0.0004737\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "# dependent variable\n",
    "# boston.keys()\n",
    "# boston.target\n",
    "y = pd.DataFrame(boston.target, columns = ['price'])\n",
    "y\n",
    "\n",
    "results= stepwise_selection(boston_features, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True)\n",
    "#     \"\"\" Perform a forward-backward feature selection \n",
    "#     based on p-value from statsmodels.api.OLS\n",
    "#     Arguments:\n",
    "#         X - pandas.DataFrame with candidate features\n",
    "#         y - list-like with the target\n",
    "#         initial_list - list of features to start with (column names of X)\n",
    "#         threshold_in - include a feature if its p-value < threshold_in\n",
    "#         threshold_out - exclude a feature if its p-value > threshold_out\n",
    "#         verbose - whether to print the sequence of inclusions and exclusions\n",
    "#     Returns: list of selected features \n",
    "#     Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "#     See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "#     \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LSTAT', 'RM', 'PTRATIO', 'DIS', 'B', 'INDUS', 'CHAS']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(results)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excluded =  ['TAX_(270, 360]', 'CRIM', 'PTRATIO', 'LSTAT', 'TAX_(360, 712]', 'AGE', 'B', 'INDUS', 'RM', 'CHAS', 'DIS', 'RAD_(6, 24]']\n",
      "new_pval[  TAX_(270, 360] ] = 0.0397110257887882\n",
      "new_pval[  CRIM ] = 3.898392697488064e-27\n",
      "new_pval[  PTRATIO ] = 7.910742574115878e-34\n",
      "new_pval[  LSTAT ] = 9.279885665959799e-122\n",
      "new_pval[  TAX_(360, 712] ] = 2.709643599750018e-19\n",
      "new_pval[  AGE ] = 1.5699822091880774e-18\n",
      "new_pval[  B ] = 1.3181127340754786e-14\n",
      "new_pval[  INDUS ] = 2.779090873336999e-36\n",
      "new_pval[  RM ] = 2.48722887100781e-74\n",
      "new_pval[  CHAS ] = 7.390623170519864e-05\n",
      "new_pval[  DIS ] = 1.996983855981312e-11\n",
      "new_pval[  RAD_(6, 24] ] = 1.9463524894118995e-08\n",
      "best_pval:  9.279885665959799e-122\n",
      "Add  LSTAT                          with p-value 9.27989e-122\n",
      "included:  ['LSTAT']\n",
      "backward\n",
      "pvalues:  LSTAT    9.279886e-122\n",
      "dtype: float64\n",
      "worst_pval:  9.279885665959799e-122\n"
     ]
    }
   ],
   "source": [
    "# step by step analysis - to check how the algorithm is working\n",
    "X=boston_features\n",
    "initial_list=[], \n",
    "threshold_in=0.01, \n",
    "threshold_out = 0.05, \n",
    "verbose=True\n",
    "\n",
    "included = []\n",
    "# included\n",
    "\n",
    "changed=False\n",
    "# changed\n",
    "#         # forward step\n",
    "\n",
    "excluded = list(set(X.columns)-set(included))\n",
    "print('excluded = ', excluded)\n",
    "\n",
    "new_pval = pd.Series(index=excluded)\n",
    "\n",
    "\n",
    "\n",
    "for new_column in excluded:\n",
    "    model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()    \n",
    "    new_pval[ new_column ] = model.pvalues[new_column] \n",
    "    print( 'new_pval[ ' , new_column , '] =' , model.pvalues[new_column] )\n",
    "\n",
    "best_pval = new_pval.min()\n",
    "print('best_pval: ', best_pval)\n",
    "if best_pval < threshold_in:\n",
    "    best_feature = new_pval.idxmin()\n",
    "    included.append(best_feature)\n",
    "    changed=True\n",
    "#             if verbose:\n",
    "    print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "    print('included: ', included)\n",
    "\n",
    "# backward step\n",
    "model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "# use all coefs except intercept\n",
    "pvalues = model.pvalues.iloc[1:]\n",
    "worst_pval = pvalues.max() # null if pvalues is empty\n",
    "print('backward')\n",
    "print('pvalues: ',pvalues)\n",
    "print('worst_pval: ',worst_pval)\n",
    "if worst_pval > threshold_out:\n",
    "    changed=True\n",
    "    worst_feature = pvalues.argmax()\n",
    "    included.remove(worst_feature)\n",
    "#             if verbose:\n",
    "    print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "#         if not changed:\n",
    "#             break\n",
    "#     return included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHAS</th>\n",
       "      <th>DIS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.542096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.623954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.623954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.331081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.297277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.274575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.315551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.335545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CHAS       DIS\n",
       "0     0.0  0.542096\n",
       "1     0.0  0.623954\n",
       "2     0.0  0.623954\n",
       "3     0.0  0.707895\n",
       "4     0.0  0.707895\n",
       "..    ...       ...\n",
       "501   0.0  0.331081\n",
       "502   0.0  0.297277\n",
       "503   0.0  0.274575\n",
       "504   0.0  0.315551\n",
       "505   0.0  0.335545\n",
       "\n",
       "[506 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[['CHAS','DIS']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the final model again in Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LSTAT', 'RM', 'PTRATIO', 'DIS', 'B', 'INDUS', 'CHAS']\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      LSTAT     RM   PTRATIO       DIS         B     INDUS  CHAS\n",
      "0 -1.275260  6.575 -1.443977  0.542096  1.000000 -1.704344   0.0\n",
      "1 -0.263711  6.421 -0.230278  0.623954  1.000000 -0.263239   0.0\n",
      "2 -1.627858  7.185 -0.230278  0.623954  0.989737 -0.263239   0.0\n",
      "   const     LSTAT     RM   PTRATIO       DIS         B     INDUS  CHAS\n",
      "0    1.0 -1.275260  6.575 -1.443977  0.542096  1.000000 -1.704344   0.0\n",
      "1    1.0 -0.263711  6.421 -0.230278  0.623954  1.000000 -0.263239   0.0\n",
      "2    1.0 -1.627858  7.185 -0.230278  0.623954  0.989737 -0.263239   0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th> <td>   0.773</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.770</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   242.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 29 Mar 2020</td> <th>  Prob (F-statistic):</th> <td>4.89e-156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:56:00</td>     <th>  Log-Likelihood:    </th> <td> -1464.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   2945.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   498</td>      <th>  BIC:               </th> <td>   2979.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>   <td>    5.0123</td> <td>    2.829</td> <td>    1.772</td> <td> 0.077</td> <td>   -0.545</td> <td>   10.570</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSTAT</th>   <td>   -5.6444</td> <td>    0.320</td> <td>  -17.629</td> <td> 0.000</td> <td>   -6.274</td> <td>   -5.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RM</th>      <td>    2.8712</td> <td>    0.388</td> <td>    7.405</td> <td> 0.000</td> <td>    2.109</td> <td>    3.633</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PTRATIO</th> <td>   -1.3564</td> <td>    0.227</td> <td>   -5.983</td> <td> 0.000</td> <td>   -1.802</td> <td>   -0.911</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DIS</th>     <td>   -9.7229</td> <td>    1.326</td> <td>   -7.333</td> <td> 0.000</td> <td>  -12.328</td> <td>   -7.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B</th>       <td>    4.0619</td> <td>    0.934</td> <td>    4.347</td> <td> 0.000</td> <td>    2.226</td> <td>    5.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>INDUS</th>   <td>   -1.2099</td> <td>    0.334</td> <td>   -3.619</td> <td> 0.000</td> <td>   -1.867</td> <td>   -0.553</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CHAS</th>    <td>    2.7988</td> <td>    0.795</td> <td>    3.519</td> <td> 0.000</td> <td>    1.236</td> <td>    4.362</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>105.185</td> <th>  Durbin-Watson:     </th> <td>   1.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 423.621</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.878</td>  <th>  Prob(JB):          </th> <td>1.03e-92</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 7.124</td>  <th>  Cond. No.          </th> <td>    96.7</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.773\n",
       "Model:                            OLS   Adj. R-squared:                  0.770\n",
       "Method:                 Least Squares   F-statistic:                     242.7\n",
       "Date:                Sun, 29 Mar 2020   Prob (F-statistic):          4.89e-156\n",
       "Time:                        16:56:00   Log-Likelihood:                -1464.7\n",
       "No. Observations:                 506   AIC:                             2945.\n",
       "Df Residuals:                     498   BIC:                             2979.\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          5.0123      2.829      1.772      0.077      -0.545      10.570\n",
       "LSTAT         -5.6444      0.320    -17.629      0.000      -6.274      -5.015\n",
       "RM             2.8712      0.388      7.405      0.000       2.109       3.633\n",
       "PTRATIO       -1.3564      0.227     -5.983      0.000      -1.802      -0.911\n",
       "DIS           -9.7229      1.326     -7.333      0.000     -12.328      -7.118\n",
       "B              4.0619      0.934      4.347      0.000       2.226       5.898\n",
       "INDUS         -1.2099      0.334     -3.619      0.000      -1.867      -0.553\n",
       "CHAS           2.7988      0.795      3.519      0.000       1.236       4.362\n",
       "==============================================================================\n",
       "Omnibus:                      105.185   Durbin-Watson:                   1.099\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              423.621\n",
       "Skew:                           0.878   Prob(JB):                     1.03e-92\n",
       "Kurtosis:                       7.124   Cond. No.                         96.7\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# based on the forward-backward feature selection using p-values, the optimal predictors for the model are:\n",
    "# ['LSTAT', 'RM', 'PTRATIO', 'DIS', 'B', 'INDUS', 'CHAS']\n",
    "# let's build a model with these variables.\n",
    "X_fin = X[results]\n",
    "print(X_fin.head(3))\n",
    "X_fin_with_intercept=sm.add_constant(X_fin)\n",
    "print(X_fin_with_intercept.head(3))\n",
    "model = sm.OLS(y,X_fin_with_intercept).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stepwise procedure mentions that `'INDUS'` was added with a p-value of 0.0017767, but our statsmodels output returns a p-value of 0.000. Use some of the stepwise procedure logic to find the intuition behind this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      LSTAT     RM   PTRATIO       DIS         B     INDUS\n",
      "0 -1.275260  6.575 -1.443977  0.542096  1.000000 -1.704344\n",
      "1 -0.263711  6.421 -0.230278  0.623954  1.000000 -0.263239\n",
      "2 -1.627858  7.185 -0.230278  0.623954  0.989737 -0.263239\n",
      "   const     LSTAT     RM   PTRATIO       DIS         B     INDUS\n",
      "0    1.0 -1.275260  6.575 -1.443977  0.542096  1.000000 -1.704344\n",
      "1    1.0 -0.263711  6.421 -0.230278  0.623954  1.000000 -0.263239\n",
      "2    1.0 -1.627858  7.185 -0.230278  0.623954  0.989737 -0.263239\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th> <td>   0.768</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.765</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   274.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 29 Mar 2020</td> <th>  Prob (F-statistic):</th> <td>1.26e-154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:04:49</td>     <th>  Log-Likelihood:    </th> <td> -1470.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   2956.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   499</td>      <th>  BIC:               </th> <td>   2985.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>   <td>    4.6839</td> <td>    2.859</td> <td>    1.638</td> <td> 0.102</td> <td>   -0.934</td> <td>   10.301</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSTAT</th>   <td>   -5.7279</td> <td>    0.323</td> <td>  -17.738</td> <td> 0.000</td> <td>   -6.362</td> <td>   -5.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RM</th>      <td>    2.9365</td> <td>    0.392</td> <td>    7.497</td> <td> 0.000</td> <td>    2.167</td> <td>    3.706</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PTRATIO</th> <td>   -1.4551</td> <td>    0.228</td> <td>   -6.396</td> <td> 0.000</td> <td>   -1.902</td> <td>   -1.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DIS</th>     <td>   -9.8979</td> <td>    1.340</td> <td>   -7.386</td> <td> 0.000</td> <td>  -12.531</td> <td>   -7.265</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B</th>       <td>    4.2733</td> <td>    0.943</td> <td>    4.531</td> <td> 0.000</td> <td>    2.420</td> <td>    6.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>INDUS</th>   <td>   -1.0529</td> <td>    0.335</td> <td>   -3.142</td> <td> 0.002</td> <td>   -1.711</td> <td>   -0.395</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>115.525</td> <th>  Durbin-Watson:     </th> <td>   1.039</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 458.585</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.977</td>  <th>  Prob(JB):          </th> <td>2.63e-100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 7.235</td>  <th>  Cond. No.          </th> <td>    96.7</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.768\n",
       "Model:                            OLS   Adj. R-squared:                  0.765\n",
       "Method:                 Least Squares   F-statistic:                     274.8\n",
       "Date:                Sun, 29 Mar 2020   Prob (F-statistic):          1.26e-154\n",
       "Time:                        17:04:49   Log-Likelihood:                -1470.9\n",
       "No. Observations:                 506   AIC:                             2956.\n",
       "Df Residuals:                     499   BIC:                             2985.\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          4.6839      2.859      1.638      0.102      -0.934      10.301\n",
       "LSTAT         -5.7279      0.323    -17.738      0.000      -6.362      -5.093\n",
       "RM             2.9365      0.392      7.497      0.000       2.167       3.706\n",
       "PTRATIO       -1.4551      0.228     -6.396      0.000      -1.902      -1.008\n",
       "DIS           -9.8979      1.340     -7.386      0.000     -12.531      -7.265\n",
       "B              4.2733      0.943      4.531      0.000       2.420       6.126\n",
       "INDUS         -1.0529      0.335     -3.142      0.002      -1.711      -0.395\n",
       "==============================================================================\n",
       "Omnibus:                      115.525   Durbin-Watson:                   1.039\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              458.585\n",
       "Skew:                           0.977   Prob(JB):                    2.63e-100\n",
       "Kurtosis:                       7.235   Cond. No.                         96.7\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results = ['LSTAT', 'RM', 'PTRATIO', 'DIS', 'B', 'INDUS', 'CHAS']\n",
    "# INDUS was added after B and before CHAS\n",
    "# it could have been removed in the backward step after its own inclusion \n",
    "# or after the backward step after the inclusion of CHAS\n",
    "# but in both cases, the p-value of INDUS was below the treshold of 0.05\n",
    "\n",
    "# the reason why the p-value is different at the time of the inclusion of INDUS as a variable and for the final model, \n",
    "# is because the models were different:\n",
    "# at the time of the inclusion, it only have 6 predictors\n",
    "# and the final model has 7.\n",
    "# let's calculate teh INDUS p-value with 6 predictors like it was at the tiem of the inclusion of INDUS as a predictor\n",
    "\n",
    "\n",
    "X_fin2 = X[['LSTAT', 'RM', 'PTRATIO', 'DIS', 'B', 'INDUS']]  # CHAS removed\n",
    "print(X_fin2.head(3))\n",
    "X_fin2_with_intercept=sm.add_constant(X_fin2)\n",
    "print(X_fin2_with_intercept.head(3))\n",
    "model2 = sm.OLS(y,X_fin2_with_intercept).fit()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# houra! we find the same value as wen INDUS was added as a predictor during stepwise selection!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Feature ranking with recursive feature elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use feature ranking to select the 5 most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n",
      "[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
      " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
      " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
      " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
      " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
      " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
      " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
      " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
      " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
      " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
      " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
      " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
      " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
      " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
      " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
      " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
      " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
      " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
      " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
      " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
      " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
      " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
      " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
      " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
      " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
      " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
      " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
      "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
      " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
      " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
      " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
      " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
      " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
      " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
      "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
      " 22.  11.9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False, False,  True,  True, False,  True, False,  True,  True,\n",
       "       False, False, False])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linreg = LinearRegression()\n",
    "print(linreg)\n",
    "\n",
    "print(y.values.ravel())\n",
    "type(y.values)\n",
    "\n",
    "selector= RFE(linreg, n_features_to_select = 5)  # RFE = Recursive Feature Elimination\n",
    "selector = selector.fit(X,y.values.ravel()) # convert y to 1d np array to prevent DataConversionWarning\n",
    "selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CRIM', 'INDUS', 'CHAS', 'RM', 'AGE', 'DIS', 'PTRATIO', 'B', 'LSTAT',\n",
      "       'RAD_(6, 24]', 'TAX_(270, 360]', 'TAX_(360, 712]'],\n",
      "      dtype='object')\n",
      "['LSTAT', 'RM', 'PTRATIO', 'DIS', 'B', 'INDUS', 'CHAS']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['CHAS', 'RM', 'DIS', 'B', 'LSTAT'], dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.columns)\n",
    "print(results)\n",
    "selected_col= X.columns[selector.support_]\n",
    "selected_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the linear regression model again using the 5 selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3= linreg.fit(X[selected_col],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.93498961,  3.43718997, -6.58036332,  4.65357304, -6.25217488]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.49739822])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, predict $\\hat y$ using your model. You can use `.predict()` in scikit-learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (506, 1)\n",
      "<class 'pandas.core.frame.DataFrame'> (506, 1)\n",
      "<class 'numpy.ndarray'> (506, 1)\n",
      "                  0\n",
      "count  5.060000e+02\n",
      "mean  -3.145486e-15\n",
      "std    4.662662e+00\n",
      "min   -2.076848e+01\n",
      "25%   -2.802424e+00\n",
      "50%   -4.573777e-01\n",
      "75%    2.407948e+00\n",
      "max    2.372079e+01\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAEICAYAAAAZeSDaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZxcZZno8d9Tve97hySd7k5CCAkEIYQEFQEFZdEhKjAsjoA6g3rlznivXsXlKuK44HVGHcQRFFBxQcQtjkGQQXaydEJYsne6O0mnO0nv+1r13D/OqVAUVb1UL6eq+vl+Pv3pqjrvOec5S52nznve8x5RVYwxxpjZ5vM6AGOMMXOTJSBjjDGesARkjDHGE5aAjDHGeMISkDHGGE9YAjLGGOOJSScgEfmJiPyr+/ptIrJ3uoIRkUdE5Eb39U0i8uw0TTdLRP4kIl0i8psJlL9QRBpD3u8UkQvd1yIi94tIh4hscT/7uIgcE5FeESmZjpjjhYjcJiI/9zqORBW+H7v7yJIYpvMBEXlseqObPYmwH03nMSfCtKf1WDmdwo93syl1KiOr6jPA8vHKichtwMmq+g/jTO+yqcQzhquAeUCJqo5OdmRVPS3k7XnAO4EKVe0TkTTg34FzVfWlaYk2SUx0u88lqpo7XhkRqQbqgbTg/qqqvwB+MaPBJRj3R+HPVbViFuZVDTypqtWxjD/RY+UE4lBVlalOJ17ERRWce1Yxk7FUAftiST5RptWgqn3u+3lAJrAzlomJSMo0xGRmgYhM6QebmZtsv4lu3IO+iJwlIttFpEdEfo1zsA0OC6+q+qyIHHHL7hWRi0TkUuDzwDVu9cNLbtknReRrIvIc0A8scT/7x9fPXu50q872iMhFY8S5wh2/060yu8L9/CvAl0Lm/5EI42a5VYsdIrILOCdseIOIXOyO+2Pgze60fgUET6s7ReQJt/ypIvJXEWl318Pfh0zrJyLynyKyUUT6gLeLSIaIfFtEDrlVeT8UkazQdSwinxKR4yLSLCIfCov930TkoLueng0Z91wRed5dJy8FqxHdYTeJSJ27repF5APR1i2QKSK/dstuF5E3hUxngYj8VkRa3On8s/v5G7a7iLxdRF4JGfdxcasx3ffPish7x5quO8wnIreKyAERaRORh0Sk2B1WLSIqIje667NVRL4QbcHc7fFDd3v1iMhTIlIVMlxF5BMish/YP4HtWyIiG0Sk2122pWHzUxE5eZxt97RbvNNdd2+WN1blvUVEtrrjbRWRt4QMe1JEvioiz7nL9JiIlLrDMkXk5+5663THnRdl3QTXcY+I7BKR94UMu8mN99vifG/qReSykOGL3XXZIyJ/BUrH2AZFIvJf7rbucF9XhAwvFqfau8kd/gcRyQEeARa466jX3WdOXCJwxw0/RkVdpskQ55jwOXcaHW58maHzFOd4eBS4P0Ici0Tkd+4yt4nI90OGfVhEdrvTfTR0fxwjnltF5OGwz74nIv/hvv6QO80ecb73Hx1jWif2Ufd9+Dp9j4jscPef50XkjJBhb8gBYwauqlH/gHTgIPC/gDScqqwR4F/d4RcCje7r5cBhYIH7vhpY6r6+DedUOXTaTwKHgNNwqgLT3M/+0R1+EzAaMu9rgC6gOEKcaUAtzgEvHXgH0AMsjzb/sPG/CTwDFAOLgFeDy+UObwAuDonr2ZBh1YACqe77HHc9fMhdrtVAK3CaO/wn7nK8FecHQCbwXWCDO/884E/AN0LW8Shwu7ucl+Mk7CJ3+F3uelsIpABvATLc921ueR9OtWEbUObG2B2yfuYH44uwbm5zt/lV7vw/jVs95E53G06CTweWAHXAJZHWu7usAzgHo1TgKNDkLnOWO6xkAtP9JLAJqHCX9W7gV2Hb40fuNN8EDAEroizfT3D2lfPdaX0vbPsq8Fd322RNYPs+CDzkljsdOBJheiePs+2Cy5AaMt5Nwem4sXQAH3RjuM59XxLy3ToAnOLG/CTwTXfYR3H2r2x3nmcD+VHWzdXAAnd7XAP0AfND4hkB/smdzsfdbSnu8BdwqqYz3HXbQ5TvoLvNr3RjygN+A/whZPifgV8DRTj73QXhx5+w7fmvIe9fV2YCy/RspBgjxNyAc5xY5G6P53j9cXEUuMNd/ixef6xMAV4CvuPuJ5nAee6w9+Icy1a42/aLwPMTiKcK57iQHzKPZpxLAwDvxvkxJMAFbtnVUdbRiX00fJ3i7O/HgXXuPG5010UGY+SAqHGPs1Dnh+5U7mfPEzkBnewGdjFO3XX4QSxSAro9wmehCSh83luAD0aI8204BzNfyGe/Am6LNv+w8euAS0Pe30zsCega4Jmw6d8NfDlkY/4sZJjgfAmWhnz2ZqA+ZB0P8PqD0XHgXJwv0QDwpgjL9FnggbDPHnV3mBygE+dLnzXOPnAbsCnkvQ9nx36buxMeCiv/OeD+Mbb7M8D73fgfwzlYXwq8HXjZLTPedHcDF4UMm49zMEwN2R4VYfvNtVGW7yfAgyHvcwE/sCjky/iOkOFRty/OF3IEODVk2NeJkIDG2Xav26fC9zucxLMlbJwXgJtCvkdfDBn2P4C/uK8/jPMdPmOs7R5lXe0A1ofEUxsyLNuN+SSgEucAnBMy/Jfh+8IY8zkT6AjZtgHcH1xh5S5kkgloAss0mQT0sZD3lwMHQuY5DGRGigPn+90Sun1Dyj0CfCTs+9YPVE0gpmeBG9zX7wzGE6XsH4B/ibSOGDsB/Sfw1bBp7cVJalFzQLS/8argFgBH1J2L62Ckgqpai/PL9DbguIg8KCILxpn+4XGGR5p3pGkuAA6raiCs7MJxpv+68cPGjVUVsM49Pe0UkU7gAzhfzKDQeZXhfHm3hZT/i/t5UJu+/vpVP86BshTn19OBKHFcHRbHeTi/9vpwDqQfA5pF5M8icuoYy3QiXncdN+KssyqcKpDQeXwe57pYNE/h7PDnu6+fxNl5L3DfB2Mfa7pVwO9Dhu3GSRqh8z0a8jq4viayfL1AO6/fz0K311jbtwwnCU5kXxpr241nQYTphu/v0Zb/AZwfIg+6VVrfEqchzRuIyA0hVS2dOGd0oVVpJ+ahqv3uy1w3vg597TppML6IRCRbRO4WpyqyG6cKslCc66OLgHZV7Yg2/mRMYJkmI3w7h+4zLao6GGW8RcBBjXxNugr4Xkh87Tg/UidyLPslztkwwPXuewBE5DIR2SROtXEnTsKMZbmrgE+F7f+LcM56Jp0DxktAzcBCEQltdVEZrbCq/lJVz3ODVJxTUNzXEUcZZ/6R5t0UoVwTsEhe35ChEqf6YyKacVZi6LixOgw8paqFIX+5qvrxkDKhy92K80v4tJDyBTqB1lLuuIOEXWcIieOBsDhyVPWbAKr6qKq+E+cX5h6cKqtoTqwbdx1X4KzzwzhnaqHzyFPVyyMsZ1B4AnqKNyag8aZ7GLgsbHimqk50e4+1fLk4VSqh+1nocoy1fVtwfvlPZF8aa9uN971owvmOhZrQ/q6qI6r6FVVdiVPl9x7ghvBy7nWHHwG34FTtFeJUOU2kBVYzUORepwmNL5pP4VTfrFPVfJx9A3deh4FiESmMtDgRPuvD+UEXdOKH3xSXKZLw7Rxtnwl3GKiUyI0TDgMfDdu/slT1+QnE8xvgQvf62ftwE5CIZAC/Bb4NzHOXeyPRl7ufKOvQje9rYfFlq+qvYMwcENF4CegFnC/UP4tIqoi8H1gbqaCILBeRd7gLO4hzUPW7g48B1TL5lm7l7rzTRORqnHrRjRHKbcbZ8T7jlr0Q+Duc+viJeAj4nDgXQyuA/znJOEP9F3CKiHzQjSVNRM4RkRWRCrtnFD8CviMi5QAislBELhlvRu649wH/Ls4F2BRxLlhnAD8H/k5ELnE/z3QvhFaIyDwRucI9QAwBvby2rSI5W0Te735hPumOswmnaqvbvfCY5c7ndBEJNuKItN2fxznYrMWpRtqJe1bBaxffx5vuD4GvuQcURKRMRNaPt77GcLmInCci6cBXgc2qGu3sPOr2VVU/8DvgNvdX/UqcKs83GGfbteBUO0W7X2ijG8P17vfyGmClG9uYxGkIsso9u+jGqTKMtO1zcA4gLe54H8I5WxiXqh4EaoCviEi6iJyH832MJg/neNEpTmOSL4dMqxmnWuoH7vczTUSCCeoYUCIiBSHT2oGzPYtF5CSc/XXKyxTFJ9zvUzHOGfqvJzjeFpwk/U0RyXG/m291h/0Q51h0mhtjgXvsG5eqtuDUKNyP8wNutzsoHecaTQswKk5jkXeNMakdwPXuPnkpzo/DoB8BHxORdeLIEZF3i0jeODkgojETgqoO49TX34RzkfManC9YJBk4F/NbcU7Ny3E2CjiZGaBNRLaPNc8wm4Fl7jS/Blylqm1R4rwCuMwt+wOcutA9E5zPV3BOoetxrks8MIkYw2Ppwdm41+L8IjrKaxcjo/kszoXHTeJUQTzOxO8Z+DTwCrAV53T9DpxrYYeB9TjboAXnl8v/wdnmPpxfnU3uOBfgXCeI5o842z544fv97i9pP86B5UycddeK00oweEB4w3Z3q2W2Azvd7QbOD52DqnrcLTPedL+H02jjMRHpwUmG6ya4viL5Jc5Brx3nonzUFoET2L634FRDHcWpO79/jPlG23b9OPv7c241x7lhMbThnLl8CqdhyWeA96hq6wSW9STgYZzksxvnrPMNN4iq6i7g33C2zTFgFc6F9om6HmebtOOs25+NUfa7OBfqW3G25V/Chn8QJ1HuwbnG8Ek3xj0413rr3PW0AOe7+xLONZrHCEkK07BM4X7pzqPO/fvXsYufiCO4f5+M0xCrEef7har+Hmc/eNA9FryKc1ybTEwXE1L95u6z/4zzQ7sDZ9tsGGMa/+LGF6xe/kPItGpwGp58351WLU5+gLFzQETBFivGzEki8hOcC7Bf9DoWkzhEpAGnwdTjXseSyOLiRlRjjDFzjyUgY4wxnrAqOGOMMZ6I6QxIRC4Vp5uFWhG5NcLw88XpsmVURK4K+fxMEXlBnK5yXnZb7xhjjJmDJn0G5Dbf3Idzp20jTgue69wWJsEy1UA+TiufDar6sPv5KYCq6n63xco2nC5SOseaZ2lpqVZXV08qTmOMmeu2bdvWqqpl45f0Riy9tK7F6YKjDkBEHsRp7nsiAalqgzsstGcCVHVfyOsmETmOc/f4mAmourqampqaGEI1xpi5S0Sm0qvLjIulCm4hr++CopGJd3lzgoisxblBKmJXJCJys4jUiEhNS0tLDGEaY4yJZ7EkoEjdN0yqHk9E5uPcMPahsP7bXpug6j2qukZV15SVxe0ZpDHGmBjFkoAaeX0fSMF+wSZERPJxulf/oqpuimH+xhhjkkAsCWgrsEycB06l43RJMla3Die45X+P8ziC34xX3hhjTPKadAJyuxC/BadL993AQ6q6U0Rul9eeQnqOOE//uxq4W0SCj6v+e5yebm8Sp0v0HSJy5rQsiTHGmISSEDeirlmzRq0VnDHGTI6IbFPVNV7HEY11xWOMMcYTloCMMcZ4whKQMcYYT8TSE4Ixce+Xmw+NOfz6dVN56roxZjrYGZAxxhhPWAIyxhjjCUtAxhhjPGEJyBhjjCesEYIxYawBgzGzw86AjDHGeMISkDHGGE9YAjLGGOMJS0DGGGM8YQnIGGOMJywBGWOM8YQlIGOMMZ6wBGSMMcYTloCMMcZ4whKQMcYYT1gCMnNW18AI9z5bz193HUNVvQ7HmDnH+oIzc85oIMD3n9jPPU/X0T04CsCZiwr5wrtXcE51scfRGTN32BmQmXMe33Wcbz+2j7WLi/nTLedxx5WrONY9yAd+tJna471eh2fMnGEJyMwpzV0DPFvbwtVnV/DjG89hVUUB15xTyYZbziMzzccX//CKVccZM0ssAZk5I6DKH148QmZaCp+/fMXrhpXlZfDZy05lU107Lx7q9ChCY+YWS0BmzthS387hjgHevWo+RTnpbxh+3TmVrK4sZOOrzfQPjXoQoTFziyUgMycEVHl6fwvVJdmcuagwYhmfT/ja+1bRP+xnc0P7LEdozNxjCcjMCQfb+unsH2Ht4mJEJGq5FfPzWVyaw/aDHXYtyJgZFlMCEpFLRWSviNSKyK0Rhp8vIttFZFRErgobdqOI7Hf/bow1cGMmY8fhDtJTfKycXzBu2dWVRbT1DXOovX8WIjNm7pr0fUAikgLcBbwTaAS2isgGVd0VUuwQcBPw6bBxi4EvA2sABba543bEFr4x4xvxB3jlSBcrF+STnur85vrl5kNRy5++MJ8/veRj+6EOqkpyZitMY+acWM6A1gK1qlqnqsPAg8D60AKq2qCqLwOBsHEvAf6qqu1u0vkrcGkMMRgzYXuP9jA4EuCsKNd+wmWkpnDagnxebuxieDR8FzbGTJdYEtBC4HDI+0b3s2kdV0RuFpEaEalpaWmJIUxjHDsOd5KXkcqSstwJj7O6qoih0QC7mrtnMDJj5rZYElCkK7gTvVo74XFV9R5VXaOqa8rKyiYcnDGhBob97D3awxkVBaT4ojc+CLe4NIfC7DR2HLbaYWNmSiwJqBFYFPK+AmiahXGNmbT61j78qqxcMH7jg1A+EVbOz6eupY8Rv1XDGTMTYklAW4FlIrJYRNKBa4ENExz3UeBdIlIkIkXAu9zPjJkR9a29pPqEiqKsSY+7rDyP0YBS39o3A5EZYyadgFR1FLgFJ3HsBh5S1Z0icruIXAEgIueISCNwNXC3iOx0x20HvoqTxLYCt7ufGTMj6tv6WFScTVrK5H9rLS7NIdUn7D/WMwORGWNiehyDqm4ENoZ99qWQ11txqtcijXsfcF8s8zVmMgZH/DR3DvL2U8tjGj891Ud1SQ77rYdsY2aE9YRgklZDWx+KcyYTq2XzcjneM0Rn//D0BWaMASwBmSTW0NpHigiLirJjnsay8jwAe06QMTPAEpBJWvWtfVQUZZ3o/SAW8/IzyM9MtWo4Y2aAJSCTlIZG/RzpHJhS9RuAiHByeR61x3sJWOekxkwrS0AmKR1q6yegUD3FBASwrDyXgRE/TZ0D0xCZMSbIEpBJSg1tffgEqopjv/4TFExiB9usd2xjppMlIJOUmjoHKcvLICMtZcrTKshKoyg7jYNtdkOqMdPJEpBJSs1dA8wvmHzvB9FUleTQ0NZvD6kzZhpZAjJJp613iO7BUeYXZE7bNKtKsukdGqW9z+4HMma6WAIySWd3s9N1znSeAVW7D6ZrsOtAxkwbS0Am6exq7gKY1jOgsrwMstJS7DqQMdPIEpBJOruauinISiMnI6auDiPyiVBVkk2DJSBjpo0lIJN0djV3c1L+9J39BFWX5NDaO0xr79C0T9uYucgSkEkqgyN+DrT0Mb9w+hNQVYlzT1FNgz0l1ZjpYAnIJJX9x3rxB3RaGyAELSzMItUn1DTYI6yMmQ6WgExSCTZAWDCNDRCCUlN8LCzMYvshOwMyZjpYAjJJZVdTNznpKRTlpM/I9CuLs3n1SDdDo/4Zmb4xc4klIJNUdjV3s2J+Pj6RGZn+ouJshv0BdjZ1z8j0jZlLLAGZpKGq7Gnu4dT5eTM2j0q3IcL2g1YNZ8xUWQIySeN4zxA9Q6MnnmI6E/Iz01hYmMWLhzpnbB7GzBWWgEzSOOA+tXRpWe6Mzmd1VZE1RDBmGlgCMknjQIubgMqn/hC6sayuLKS5a5DmLntAnTFTYQnIJI0DLX1kp6fMSC8IoVZXFgGw/aBVwxkzFZaATNI40NLL0rJcZIZawAWtmJ9PRqrPquGMmSJLQCZpHDjey9Kyma1+A0hP9XFGRYElIGOmyBKQSQr9w6M0dQ3OeAOEoNWVRey0G1KNmRJLQCYp1LU4j0lYWj47CeisyiKG/QFePWI3pBoTq5gTkIhcKiJ7RaRWRG6NMDxDRH7tDt8sItXu52ki8lMReUVEdovI52IP3xjHiRZws3UGVFUIwItWDWdMzGJKQCKSAtwFXAasBK4TkZVhxT4CdKjqycB3gDvcz68GMlR1FXA28NFgcjImVgda+vAJVJdmz8r8yvMyqSiyjkmNmYpYz4DWArWqWqeqw8CDwPqwMuuBn7qvHwYuEqd5kgI5IpIKZAHDgNVjmCk50NJLZXE2GakpszbP1ZVF1hTbmCmINQEtBA6HvG90P4tYRlVHgS6gBCcZ9QHNwCHg26r6hgesiMjNIlIjIjUtLS0xhmnmCqcF3OxUvwWtrizkaPcgTZ12Q6oxsYg1AUW60UInWGYt4AcWAIuBT4nIkjcUVL1HVdeo6pqysrIYwzRzgT+g1Lf2zVoDhKDVVe4NqVYNZ0xMYk1AjcCikPcVQFO0Mm51WwHQDlwP/EVVR1T1OPAcsCbGOIyhqXOAodHArNwDFGrF/Hwy03xWDWdMjGJNQFuBZSKyWETSgWuBDWFlNgA3uq+vAp5QVcWpdnuHOHKAc4E9McZhDLVuC7gls1wFl5bi44yFhXYGZEyMUmMZSVVHReQW4FEgBbhPVXeKyO1AjapuAO4FHhCRWpwzn2vd0e8C7gdexammu19VX57icpg56JebDwHwXG0rAC8e6mT/sd5ZjeGsqkLue7aewRE/mWmz1wDCmGQQUwICUNWNwMawz74U8noQp8l1+Hi9kT43JlZtfcNkpPrISZ/9BLC6soi7/XXsbOri7KriWZ+/MYnMekIwCa+9b4iS3PQZ74Q0krMqnRtS7TqQMZNnCcgkvLbeYUpyMjyZt92QakzsLAGZhOYPKB39w5TkpHsWw+pK5wmpThsbY8xEWQIyCa2zf5iAQkmulwmokGPdQzR1DXoWgzGJyBKQSWhtfcMAnlXBQcgNqQetGs6YybAEZBJaW+8Q4O0Z0IkbUu06kDGTYgnIJLTWvmHSU33kZsR8R8GUvXZDqrWEM2YyLAGZhNbe6zRA8KIJdqizqgrZ1dTF4Ig9IdWYibIEZBJaW9+Qpy3gglZXFjHiV1490uV1KMYkDEtAJmH5A0pH3wglud41QAhaXWk9YxszWZaATMLqGhjBrxoXZ0BleRksKs5im7WEM2bCLAGZhPVaCzjvz4AA1lQVs+2g3ZBqzER513TImCl67R4g78+AAM6pLub3Lx7hzv+upTQvclK8fl3lLEdlTPyyMyCTsNp6h0hLEfIy4+N31NrFznWghrY+jyMxJjFYAjIJq63P6YTU6ybYQUvLcslOT7EEZMwExcdPR2Ni0NY7THn+7F//CT4IL5Lqkhwa2vpnMRpjEpedAZmE5A8o7R73gh1JVUk27X3DdA+MeB2KMXHPEpBJSM1dA/gD6mknpJFUl+QAdh3ImImwBGQSUkOrU81V7GEnpJEsKMwiLUWsGs6YCbAEZBJS8AyjNE7uAQpK8QmVxdkctDMgY8ZlCcgkpINtfaT64qcJdqjqkhyOdg0yMGwdkxozFktAJiE1tPVTnJOOL06aYIeqKslBgUPtdhZkzFgsAZmE1NDaF3fVb0GVxdn4BLsOZMw4LAGZhBMIKAfb++OuCXZQeqqPBYVZ1hLOmHFYAjIJ52j3IMOjgbhrARequiSHxo4BRvwBr0MxJm5ZAjIJp6HVObOIt3uAQlWX5OAPKI0dA16HYkzcsgRkEk7w2kppHJ8BVZVkA1hzbGPGEFMCEpFLRWSviNSKyK0RhmeIyK/d4ZtFpDpk2Bki8oKI7BSRV0QkM/bwzVx0sK2P9FQf+VlpXocSVU5GKmV5GXYdyJgxTDoBiUgKcBdwGbASuE5EVoYV+wjQoaonA98B7nDHTQV+DnxMVU8DLgSs0ywzKQ1tfW5Ls/hrgh2quiSHg239BOwBdcZEFMsZ0FqgVlXrVHUYeBBYH1ZmPfBT9/XDwEXi9Jn/LuBlVX0JQFXbVNXu1jOT0tDaT7VbxRXPqkuyGRoNcLRr0OtQjIlLsSSghcDhkPeN7mcRy6jqKNAFlACnACoij4rIdhH5TLSZiMjNIlIjIjUtLS0xhGmSkdMEu+9Ep5/xrLrUOiY1ZiyxJKBI9R7hdQzRyqQC5wEfcP+/T0QuijQTVb1HVdeo6pqysrIYwjTJ6HjPEIMjgRMX+eNZYVYaBVlpdkOqMVHEkoAagUUh7yuApmhl3Os+BUC7+/lTqtqqqv3ARmB1DDGYOaqutReAJWW5HkcyPhGhqsTpmFTtOpAxbxBLAtoKLBORxSKSDlwLbAgrswG40X19FfCEOt/AR4EzRCTbTUwXALtiC93MRXUtTnXW4tL4r4IDpyFCz+Ao7X3DXodiTNyZdFfCqjoqIrfgJJMU4D5V3SkitwM1qroBuBd4QERqcc58rnXH7RCRf8dJYgpsVNU/T9OymDmgvrWPzDQfJ+UnRuv9164D9VMSp33XGeOVmPqyV9WNONVnoZ99KeT1IHB1lHF/jtMU25hJq2/tY3FpLj5ffDfBDirPyyArLYWGtj7OriryOhxj4or1hGASSl1LL0sSpPoNwOdeBwp2H2SMeY0lIJMwhkcDHO4YSJjrP0HVJTm09Q3TM2j3XBsTyhKQSRiHO/rxB5QlZYmWgIL9wllzbGNCWQIyCSPRWsAFLSjKIi1F7IZUY8JYAjIJoz54D1Bp/N8DFCrV56OiKNsSkDFhLAGZhFHf2kdJTjoF2fHbC3Y01SU5NHcO2nUgY0JYAjIJ40BLX8JVvwVVl2SjwIuHOr0OxZi4YQnIJIz61r6Ea4AQVFmcjQBbG9q9DsWYuGEJyCSEnsERWnqGWJxg13+CMtJSWFCYxZZ6S0DGBFkCMgmhvjUxW8CFqi7JZsfhToZG7RFYxoAlIJMgggloaYJWwQFUleQwNBrg1SNdXodiTFywBGQSwoGWPnwCi4rj/zlA0QSfYbS1ocPjSIyJD5aATELYf6yHqpIcMtNSvA4lZnmZaSwpzWGrXQcyBrAEZBLEvmM9LCtPzAYIoc6pLqbmYAeBgD2gzhhLQCbuDY36aWjrZ/lJeV6HMmXnLC6ma2CEfcd7vA7FGM9ZAjJxr66lD39AWTYv8RPQusXFAGw60OZxJMZ4zxKQiXv7jjlnC8uTIAEtKs6moiiLF+osARljCcjEvX3Hekj1SULfAxTqLUtL2FTXjt+uA5k5zhKQiXt7j/ZSXZpDempy7K5vWVpK18AIu5u7vQ7FGE8lx/MoAPQAABbKSURBVDfaJLX9x3uSovot6M1LSwB4/kCrx5EY4y1LQCauDQz7OdTez7J5id8EO2hefiZLy3J43hoimDnOEpCJa7XHe1FNjgYIod6ytJQt9e2M+ANeh2KMZywBmbgWbAGXDE2wQ71laQn9w35ebrTnA5m5yxKQiWv7jvWQnuKjuiRx+4CL5NwlJYjA87VWDWfmLktAJq7tO9bDkrIcUlOSa1ctykln5fx8nq21hghm7kqub7VJOvuO9XJKklW/BV1wShnbDnbQPTjidSjGeCLV6wCMiebHT9dxpHOAVQsL+OXmQ16HM+3efmo5P3jyAM/ub+XyVfO9DseYWRfzGZCIXCoie0WkVkRujTA8Q0R+7Q7fLCLVYcMrRaRXRD4dawwmuR3pHABgYVGWx5HMjLMWFZKfmcrf9hz3OhRjPBFTAhKRFOAu4DJgJXCdiKwMK/YRoENVTwa+A9wRNvw7wCOxzN/MDcEEtKAgORNQaoqP808p48l9LfZ4BjMnxXoGtBaoVdU6VR0GHgTWh5VZD/zUff0wcJGICICIvBeoA3bGOH8zBxzpHKA4J52s9MR9CN143r68nJaeIXZZtzxmDoo1AS0EDoe8b3Q/i1hGVUeBLqBERHKAzwJfGWsGInKziNSISE1LS0uMYZpEdqRzgIWFyXn2E3TB8jIAq4Yzc1KsCUgifBZehxCtzFeA76hq71gzUNV7VHWNqq4pKyuLMUyTqNr7hunsH0n6BFSam8GbKgr4215LQGbuiTUBNQKLQt5XAE3RyohIKlAAtAPrgG+JSAPwSeDzInJLjHGYJPXKkS4geRsghLpweTkvHu6krXfI61CMmVWxJqCtwDIRWSwi6cC1wIawMhuAG93XVwFPqONtqlqtqtXAd4Gvq+r3Y4zDJKlX3QSUrA0QQr1z5TxU4bFdx7wOxZhZFVMCcq/p3AI8CuwGHlLVnSJyu4hc4Ra7F+eaTy3wv4E3NNU2JpqXGzspSfIGCEGnLcinqiSbja80ex2KMbMq5htRVXUjsDHssy+FvB4Erh5nGrfFOn+T3F490j0nqt8ARITLV83nnqfraO8bpjgn3euQjJkV1hWPiTttvUNzogVcqHevmo8/oDy286jXoRgza6wrHhN3Xg5e/0nCBBStSyFVpbI4mz+/0sy1aytnOSpjvGFnQCbu1DS0k+oTFhUl1yMYxhKshnv+QBsdfcNeh2PMrLAEZOLOlvp2TltYQHrq3No9g9Vwj1o1nJkj5tY33MS9wRE/Lx3uYt3iYq9DmXWnL8xncWkOv3vxiNehGDMrLAGZuPLS4U6G/QHWVs+9BCQiXHV2BVvq2znY1ud1OMbMOEtAJq5sqW9HBM6ZgwkI4P2rF+ITeHhbo9ehGDPjrBWciStbGtpZPi+Pguw0r0OZdcEWckvLcvnZCweZl5+JT17rUvH6ddY6ziQXOwMycWPEH2DbwQ7WzsHrP6HOriqia2CEAy1j9tdrTMKzBGTixs6mbvqH/XM+Aa2Yn09mmo9tBzu8DsWYGWUJyMSNLfVtAHOyAUKotBQfZy4qZFdTN31Do16HY8yMsQRk4samunaqS7Ipz8/0OhTPrVtcwmhA7SzIJDVLQCYuDI74eeFAG+efYg8fBJiXn8ni0hw217cR0PBnPRqTHCwBmbiwpb6dgRE/Fy63BBS0bnExHf0j7DvW43UoxswIS0AmLjy5t4X0VB9vXlLqdShx47QFBeRlprK5rt3rUIyZEXYfkPFU8N6XDS8doao4m99bNzQnpPiEc6qL+due4/a4bpOU7AzIeK6td4jW3mGWn5TndShxZ211MT4RXqhr8zoUY6adJSDjueA1juXzLAGFy89K44yKAmoOdtA1MOJ1OMZMK0tAxnN7j/VQkpNOSW6G16HEpbeeXMrwaIAHt0R+mJ0xicoSkPHUiD9AXUsfp1j1W1QLCrNYUpbDT55vYMQf8DocY6aNJSDjqX3HehgNKCtOyvc6lLj2tpNLae4a5M8vN3sdijHTxhKQ8dQrR7rITk9hcWmO16HEtWXz8ji5PJe7n65D7cZUkyQsARnPDI742XO0h9MW5JPik/FHmMN8Inz8gqXsbu7miT3HvQ7HmGlhCch45ql9LQyPBjh9QYHXoSSEK85cQEVRFnc+UWtnQSYpWAIynnnklWay0lJYUpbrdSgJIS3Fx8cvXMqOw508V2v3BZnEZwnIeGJwxM/ju49b9dskXXV2BfPyM7jzif1eh2LMlFkCMp54Zn8rvUOjnL7Qqt8mIyM1hY+ev5TN9e08u7/V63CMmZKYEpCIXCoie0WkVkRujTA8Q0R+7Q7fLCLV7ufvFJFtIvKK+/8dUwvfJKo/7jhCUXYaS636bdKuX1fJwsIsvvHIbgIBuxZkEtekE5CIpAB3AZcBK4HrRGRlWLGPAB2qejLwHeAO9/NW4O9UdRVwI/BArIGbxNU1MMJju45xxZsWWPVbDDLTUvj0Jaews6mbP73c5HU4xsQsljOgtUCtqtap6jDwILA+rMx64Kfu64eBi0REVPVFVQ1+Y3YCmSJi/a/MMX9+uZnh0QBXnl3hdSgJa/2bFrJyfj7f+stehkb9XodjTExiSUALgcMh7xvdzyKWUdVRoAsoCStzJfCiqkbsZ15EbhaRGhGpaWlpiSFME68e3naYZeW5rLLrPzHz+YTPX76CI50D3PtsvdfhGBOTWBJQpDqT8IroMcuIyGk41XIfjTYTVb1HVdeo6pqyMntKZrKoa+ll+6FOrjy7AhGrfpuK85aV8q6V8/je4/upa+n1OhxjJi2WB9I1AotC3lcA4RXRwTKNIpIKFADtACJSAfweuEFVD8Qwf5PAfrf9CD6B950VftJsxhN8eF+o1ZVFPL2/hVt/+woP3nwuPrumZhJILGdAW4FlIrJYRNKBa4ENYWU24DQyALgKeEJVVUQKgT8Dn1PV52IN2iQmf0D53fZGzltWxrz8TK/DSQr5WWlcfvp8tjS084vNB70Ox5hJmXQCcq/p3AI8CuwGHlLVnSJyu4hc4Ra7FygRkVrgfwPBptq3ACcD/1dEdrh/5VNeCpMQnthznKauQa5fu2j8wmbCzq4q4m3LSvnaxt3sbOryOhxjJkwSoU+pNWvWaE1NjddhmCm64b4t7D3azXOffQepKc5vn0jVSmbyLl5ZzhV3PkeKT9hwy1vf8HC/sdbz9esqZzo84xER2aaqa7yOIxrrCcHMiobWPp7e18L1a6tOJB8zfcrzMrnnhrNp7R3i47/YzvCoPbjOxD87EphZ8YvNB0n1Cdda9duMOaOikDuuPIMt9e38j19st/uDTNyzBGRm3OCIn4dqGrnktJOs8cEMe+9ZC7l9/Wk8vvsYH31gG4MjloRM/LIEZGbc77YfoWtghH84t8rrUOaEG95czTfev4qn9rVww71baOuNeK+3MZ6zBGRm1Kg/wN1PH+CMigLOXVLsdThzxnVrK/nuNWeyo7GT9Xc9R3PXgNchGfMGsdyIasyEfeEPr3KwrZ/r11byqy2Hxx/BxCRaK7d/PG8xD2w6yN1P1fH3aypYaU+fNXHEzoDMjFFVnt7XQlluBisX5HsdzpxUUZTNJy48mfL8DH6++RBP7Dluj/M2ccMSkJkxT+5roblrkPNPKcNn/b55Jj8rjX962xLOXFTI47uP8eDWw9ZM28QFq4IzMyIQUL77+H4KstJ40yKr9vFaWoqPq8+u4KT8TB7deZS2viH+YV0VhdnpXodm5jA7AzIz4k8vN/HS4U4uXjGPVJ/tZvFARDj/lDI+eG4Vbb3D/OeTB2jqtMYJxjt2ZDDTbnDEz7f+speV8/M5q7LQ63BMmFPn5/OxC5bi8wk/eqaO52pbvQ7JzFGWgMy0u/+5Bo50DvDFd6+waz9xal5+Jh+7YCmF2WncdP8W/rjjiNchmTnIEpCZVs1dA/zgb7VcvKKct5xc6nU4ZgwFWWnc/LalrK4s4l8e3MGPnq7zOiQzx1gCMtMmEFA+8/DLjAaUL757pdfhmAnISk/hpx9ey7tXzedrG3fz1f/aRSBgzbTN7LBWcGba/OyFBp7Z38rX37eK6tIcr8MxE5SZlsKd151FeX4G9z5bz7HuQf7t799ERmqK16GZJGcJyEyL/cd6+MYje3jHqeVcZz1eJxyfT/jSe1YyvyCTr2/cQ2vvEHdet5qyvIzxRzYmRlYFZ6bsWPcgN92/lbzMVL555SrEGh4kJBHh5vOX8r1rz+TFQ51c9r1neGZ/i9dhmSRmCchMSffgCDfet4WO/mHuu+kcyvPscQuJbv2ZC/njLW+lMDuNG+7bwpf/+CrdgyNeh2WSkCUgE7O23iE+dP9WDrT0cvcHz+aMCrvnJ1mcelI+f7rlPG44t4qfbTrIRf/2FL9/sdEaKJhpJYnQMeGaNWu0pqbG6zBMiF1N3fzTz2po6R3iytUVrFpo3e0kq9MX5vOF37/KK0e6WDE/n89cspwLl5dZVWsCEJFtqrrG6ziisTMgMylDo37ufuoAV/7n8/gDym8++mZLPknujIpC/viJt/K9a8+kb2iUD/1kK9fcvYmahnavQzMJzs6AzIQMjfr5y6tH+c5f99HQ1s9Fp5bzjStXUZ6XGfVZNCb5jAYC1DR08Lc9x+kZGuWiU8v59CXLWTF/8o/bGG+/uX5dZaxhGle8nwFZM2wT1ag/wPZDnTy28yi/e/EI7X3DLCvP5acfXssFp5R5HZ7xQKrPx7lLSlhdWcQLB1p5oa6Ny//jGd575kL+18WnUFmS7XWIJoFYAjInqCr7j/eyqa6NTXVtPH+gjc7+EdJShItXzOP6dZW8dWkpPp/V/c916ak+LlhezreuehM/fPoA9z9Xz3+93MS151Ty0QuWUFFkiciMz6rg5jBVpdZNOL+uaaS+pZe+YT/g9BO2tCyH5Sfls6w8l8w0uyveRNc9OMLf9hxna0M7qrD8pDxWVxbxmUuXR33mULAKTlUZ8SuqSlqq70QHtlYFN3XxXgVnCWgOUVUOtPSxqa6NF+ra2FzXRmvvMOAknCWlOSwpy2FxaS5F2WnWyslMWmf/MFsa2qlp6KB3aBQRWD4vj5MKMinOTsevSmf/CJ39wxzuGGBg2M/giJ/Qo1BailCUnc4ZFYWsXJDP2upizqosJCfDKmwmK94TkG3RJKWqNHYMsLOpm13N3exq6ualxk5aeoYAOCk/k7ctK+PNS0o4d0kJz+xvsYRjpqwwO513rTyJd5xazuH2AfIyU9l+qIO23mH2H+slNUUozEo7cVaUlZ5CZloKGakp+ARG/AEGRwK09w1zqL2PJ/YcI6CQ4hNWzs/nnOpi1i4u4pzqYkpyrZugRBfzGZCIXAp8D0gBfqyq3wwbngH8DDgbaAOuUdUGd9jngI8AfuCfVfXRseYVD2dAA8N+OgeGGfUrf9zRRFqKkJmWQlrKG1uyz2bVQdfACPWtfTS09rHhpSbaeodo7R2mtXeIodEAAAKU5WWwoDCLxaU5LCnNoTgn3RKOmXFjfRcm0npycMTP4fZ+Gtr6aWjro7GjnxG/c8xaVp7L2sXFrF1czGkL8qkuySE1wvdxPIGA0jUwQlvfMO19w2x8pRl/QBnxBxgNKP6AEvymiAgCBL86wfcIpKf4uOLMBRRmpVGQnUZhVjrpqd7e6ZKUZ0AikgLcBbwTaAS2isgGVd0VUuwjQIeqniwi1wJ3ANeIyErgWuA0YAHwuIicoqr+qSzIWIJ1zCP+AKN+ZdgfYMQfYGg0QEf/MJ39w3T0jdDRP0xH/zBtvcO09g7T1jdEa+8Qbb3D9A9HDi/VJ2Slp5CVlkJORiq5GansO9ZDaW46JbkZlOZmUJqbTl5mKhmpzq+9zDTfiWsqAVVUQdV57fxB//AoPYOj9AyO0DM4StfACEe7BmnuGqSpc4DmrkGOdA7Q3jd8IhYBCrPTKMnN4MxFhcwvyGJ+QSbz8jM9/yIYE4vMtBSWzctj2bw8wGkG3tQxQEF2Olvq29iwo4lfuIksI9VHdUkOFUVZzCvIJD8zjdyMFEQEVWVgxE97n1P91+F+59v7naTjn6YeHh7YdPB17/MzUynPz2Refgbz8jIpc/+X52dQnJ1OTkaq++ccP9JTfKT6hBSfzIkfiLFWwa0FalW1DkBEHgTWA6EJaD1wm/v6YeD74qzR9cCDqjoE1ItIrTu9F2KMJapvPrKHHz9Tx+gkdq4Un1Cck34icVQVZ1OSm0FJbjqFWemkpghb6toZ9gcYHPEzMOLUYfcP++kbGqW5a4Dfbu+jZ3B0uhcHgLyMVOYXZjK/IIvTFxawuDSb6pIcFpfm8PyBtohnZMYki1Sfj8qSHK5fV8nHL1yKP6DsO9bDrqZudjd3c7C9nyMdA+w43EnP4CjD/sCJcVN8QlG2U/1XlJ1GZUk2q6sKKcnJoDgnnZLcdIpz0nlufyspbiIIJgPAuU6lzn9VPfE+gPMjctSvnLu02LnGNTBCV7/zQ/ZY9yDHugfZ0tDO8e6h18U0Fp84y3vn9WdxyWknTfeqjAuxJqCFwOGQ943AumhlVHVURLqAEvfzTWHjLgyfgYjcDNzsvu0Vkb0xxjppMT4XshRondZAonh1NmYytllb1jhgyzoFH5jOiU3vdBNmu1769SmNXjVNYcyIWBNQpHPD8NOMaGUmMi6qeg9wz+RD84aI1MRzXet0smVNTrasZrbFWl/TCIQ+dawCaIpWRkRSgQKgfYLjGmOMSXKxJqCtwDIRWSwi6TiNCjaEldkA3Oi+vgp4Qp0mdxuAa0UkQ0QWA8uALTHGYYwxJkHFVAXnXtO5BXgUpxn2faq6U0RuB2pUdQNwL/CA28igHSdJ4ZZ7CKfBwijwiZlsATeLEqa6cBrYsiYnW1YzqxKiJwRjjDHJx9rsGmOM8YQlIGOMMZ6wBDQFIvL/RGSPiLwsIr8XkcKQYZ8TkVoR2Ssil3gZ53QQkatFZKeIBERkTdiwpFpWcLqacpenVkRu9Tqe6SYi94nIcRF5NeSzYhH5q4jsd/8XeRnjdBCRRSLyNxHZ7e6//+J+nnTLmogsAU3NX4HTVfUMYB/wOYCw7oYuBX7gdl+UyF4F3g88HfphMi5rSFdTlwErgevc5UwmP8HZXqFuBf5bVZcB/+2+T3SjwKdUdQVwLvAJd1sm47ImHEtAU6Cqj6lqsM+dTTj3NEFId0OqWg8EuxtKWKq6W1Uj9UaRdMtKSFdTqjoMBLuaShqq+jRO69RQ64Gfuq9/Crx3VoOaAararKrb3dc9wG6cnleSblkTkSWg6fNh4BH3daSuit7Q3VCSSMZlTcZlmoh5qtoMzoEbKPc4nmklItXAWcBmknxZE4U9D2gcIvI4EKknwC+o6h/dMl/AOdX/RXC0COXjvr37RJY10mgRPov7ZR1HMi7TnCYiucBvgU+qavdc6Gk6EVgCGoeqXjzWcBG5EXgPcJG+dlNVQnY3NN6yRpGQyzqOZFymiTgmIvNVtVlE5gPHvQ5oOohIGk7y+YWq/s79OCmXNdFYFdwUuA/l+yxwhar2hwyaS90NJeOyTqSrqWQU2n3WjUC0s96E4T4C5l5gt6r+e8igpFvWRGQ9IUyB281QBs4TXwE2qerH3GFfwLkuNIpz2v9I5KkkBhF5H3AnUAZ0AjtU9RJ3WFItK4CIXA58l9e6mvqaxyFNKxH5FXAhzmMJjgFfBv4APARUAoeAq1U1vKFCQhGR84BngFeA4IN4Po9zHSipljURWQIyxhjjCauCM8YY4wlLQMYYYzxhCcgYY4wnLAEZY4zxhCUgY4wxnrAEZIwxxhOWgIwxxnji/wO8QL3Oj9oExgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here\n",
    "yhat = model3.predict(X[selected_col])\n",
    "print(type(yhat),yhat.shape)\n",
    "print(type(y), y.shape)\n",
    "y2=y.values\n",
    "print(type(y2), y2.shape)\n",
    "diff = pd.DataFrame(y2-yhat)\n",
    "print(diff.describe())\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.distplot(diff)\n",
    "plt.title(\"distrib of differences between predictions and actual 'price' values\" )\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using the formulas of R-squared and adjusted R-squared below, and your Python/numpy knowledge, compute them and contrast them with the R-squared and adjusted R-squared in your statsmodels output using stepwise selection. Which of the two models would you prefer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$SS_{residual} = \\sum (y - \\hat{y})^2 $\n",
    "\n",
    "$SS_{total} = \\sum (y - \\bar{y})^2 $\n",
    "\n",
    "$R^2 = 1- \\dfrac{SS_{residual}}{SS_{total}}$\n",
    "\n",
    "$R^2_{adj}= 1-(1-R^2)\\dfrac{n-1}{n-p-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price    0.742981\n",
      "dtype: float64\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "price    0.740411\n",
       "dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "SS_res = np.sum( (y - yhat)**2  )\n",
    "SS_total = np.sum( (y - np.mean(y))**2)\n",
    "Rsq = 1-SS_res/SS_total\n",
    "print(Rsq)\n",
    "print(X[selected_col].shape[1])\n",
    "Rsqadj =1- (1-Rsq)*(len(y) - 1)/ (len(y) - X[selected_col].shape[1] - 1)\n",
    "Rsqadj\n",
    "# r_squared is 0.742981  \n",
    "# adjusted_r_squared is 0.740411"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level up (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Perform variable selection using forward selection, using this resource: https://planspace.org/20150423-forward_selection_with_statsmodels/. Note that this time features are added based on the adjusted R-squared!\n",
    "- Tweak the code in the `stepwise_selection()` function written above to just perform forward selection based on the p-value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Great! You practiced your feature selection skills by applying stepwise selection and recursive feature elimination to the Boston Housing dataset! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True,  True, False,  True,  True,  True,  True,\n",
       "       False, False,  True])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Would we find the same best predictors as with stasmodel forward-backward feature selection using p-values\n",
    "# if we had asked 7 to scikit-learn RFE?\n",
    "selector2= RFE(linreg, n_features_to_select = 7)  # RFE = Recursive Feature Elimination\n",
    "selector2 = selector2.fit(X,y.values.ravel()) # convert y to 1d np array to prevent DataConversionWarning\n",
    "selector2.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CRIM', 'INDUS', 'CHAS', 'RM', 'AGE', 'DIS', 'PTRATIO', 'B', 'LSTAT',\n",
      "       'RAD_(6, 24]', 'TAX_(270, 360]', 'TAX_(360, 712]'],\n",
      "      dtype='object')\n",
      "['LSTAT', 'RM', 'PTRATIO', 'DIS', 'B', 'INDUS', 'CHAS']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['CHAS', 'RM', 'DIS', 'PTRATIO', 'B', 'LSTAT', 'TAX_(360, 712]'], dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.columns)\n",
    "print(results)\n",
    "selected_col2= X.columns[selector2.support_]\n",
    "selected_col2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Would we find the same best predictors as with stasmodel forward-backward feature selection using p-values\n",
    "# if we had asked 7 to scikit-learn RFE? \n",
    "# NO! :( \n",
    "#?????"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
